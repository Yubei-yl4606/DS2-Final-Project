---
title: "Investigating indicators that can tell if the breast cancer is malignant project"
author: 
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(klaR)
library(tidyverse)
library(AppliedPredictiveModeling)
library(caret)
library(glmnet)
library(pROC)
```

```{r}
#read data and remove useless columns
bc = read.csv("data.csv") %>% 
     select(diagnosis, symmetry_mean, contains(c("texture")), smoothness_mean, smoothness_worst, symmetry_se, 
                  fractal_dimension_se, symmetry_worst, concavity_se, concave.points_se) %>% 
        mutate(diagnosis = as.factor(diagnosis))
```
## Introduction:   
  The breast cancer is one of the leading deaths causes among women, and the correct prediction of the cancer is benign or malignant could have significant impact on further decisions, such as further screening and preventative actions (Stark, Hart, Nartowt and Deng, 2019). In this report, we are trying to use about 10 different variables to predict the binary outcome (benign or malignant) of the diagnosis of breast cancer. We hope to build a model that performs well on predicting the nature of the breast cancer based on different predictors such as the mean radius, perimeter and the area of the tumor. Our data was downloaded from KAGGLE, and the data are relatively pretty clean. We have removed the ID column and the “X” column which both are meaningless in predicting. Then, we have checked the number of missing values, and luckily, there are 0 missing value in our data. Furthermore, I have converted the outcome benign as 0 and malignant as 1 for convenience.

### Data cleaning:   
  For data tidying, I simply converted variable diagnosis from class character into class factor for further analysis. I also checked for a number of missing data and there was none. So I separated the data into training(80%) and testing(20%) sets.

## Explotary Analysis/Visulization:
  This original data set contains 30 different predictors and they are generated by the ten features:
a) radius, b) texture (standard deviation of gray-scale values), c) perimeter, d) area, e) smoothness (local variation in radius lengths), f) compactness (perimeter^2 / area - 1.0), g) concavity (severity of concave portions of the contour), h) concave points (number of concave portions of the contour), i) symmetry, j) fractal dimension. The mean, standard error and "worst" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. (Breast Cancer Wisconsin (Diagnostic) Data Set, 2021).  
  However, we only kept 10 of the 30 variables from the original dataset, because some of the variables are too informative, and as the result, 
    we kept the standard error of concave points, the standard error of fractal dimension, the standard error of symmetry, the standard error of concavity, the standard error of texture, the mean of smoothness, the mean of symmetry, the mean of texture, the worst of symmetry and the worst of texture as our predictors. Since these predictors are related to tumors, but are not very informative and would not determine if the tumor is malignant or not by themselves, we believe these are good predictors for this project.  

## Models:
We have divided the dataset into train set and test set for further checking performance of the models.  
```{r}
set.seed(2021)
indexTrain <- createDataPartition(y = bc$diagnosis, p = 0.80, list = FALSE)
trainData <- bc[indexTrain, ]
testData <- bc[-indexTrain, ]
```
### Lasso regression:   
```{r}
x = as.matrix(trainData[2:12])
y = trainData$diagnosis
set.seed(2021)
cv.lasso <- cv.glmnet(x, y, 
                      alpha = 1, 
                      lambda = exp(seq(5, -5, length = 1000)),
                      family = "binomial")
cv.lasso$lambda.min
coef = predict(cv.lasso, s = "lambda.min", type = "coefficients")
lasso.pred = predict(cv.lasso, newx = as.matrix(testData[2:12]), s = "lambda.min", type = "response")
roc.lasso <- roc(testData$diagnosis, lasso.pred)
roc.lasso$auc
```

### Logistic regression with penalization: (待修改，就是glmnet的模型)
```{r}
ctrl <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE)
glmnGrid <- expand.grid(.alpha = seq(0, 1, length = 6),
                        .lambda = exp(seq(-8, -2, length = 20)))
set.seed(1)
model.glmn <- train(x = trainData[2:11],
                    y = trainData$diagnosis,
                    method = "glmnet",
                    tuneGrid = glmnGrid,
                    metric = "ROC",
                    trControl = ctrl)
plot(model.glmn, xTrans = function(x) log(x))
glmn.pred = predict(model.glmn, newdata = testData, type = "prob")[,2]
roc.glmn <- roc(testData$diagnosis, glmn.pred)
plot(varImp(model.glmn, scale = FALSE), top = 10, main = "glmnet")
roc.glmn$auc
```

